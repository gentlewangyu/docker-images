
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
  <property>
    <name>dfs.block.access.token.enable</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.block.replicator.default.local.rack</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.blockreport.incremental.intervalMsec</name>
    <value>300</value>
  </property>
  <property>
    <name>dfs.blockreport.initialDelay</name>
    <value>60</value>
  </property>
  <property>
    <name>dfs.blockreport.intervalMsec</name>
    <value>43200000</value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value>268435456</value>
  </property>
  <property>
    <name>dfs.client.failover.proxy.provider.ns1</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.data.transfer.protection</name>
    <value>integrity</value>
  </property>
  <property>
    <name>dfs.datanode.address</name>
    <value>0.0.0.0:61004</value>
  </property>
  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>104857600</value>
  </property>
  <property>
    <name>dfs.datanode.balance.max.concurrent.moves</name>
    <value>112</value>
  </property>
  <property>
    <name>dfs.datanode.cached-dfsused.check.interval.ms</name>
    <value>14400000</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file:///data1/hdfs,file:///data2/hdfs,file:///data3/hdfs,file:///data4/hdfs</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>700</value>
  </property>
  <property>
    <name>dfs.datanode.du.reserved</name>
    <value>10737418240</value>
  </property>
  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.datanode.handler.count</name>
    <value>20</value>
  </property>
  <property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:61006</value>
  </property>
  <property>
    <name>dfs.datanode.max.transfer.threads</name>
    <value>8192</value>
  </property>
  <property>
    <name>dfs.datanode.max.xcievers</name>
    <value>8192</value>
  </property>
  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/lib/hadoop-hdfs/dn_socket</value>
  </property>
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>shell(/bin/true)</value>
  </property>
  <property>
    <name>dfs.ha.namenodes.ns1</name>
    <value>nn1,nn2</value>
  </property>
  <property>
    <name>dfs.hosts.exclude</name>
    <value>/etc/apps/hadoop-conf/dfs.exclude</value>
  </property>
  <property>
    <name>dfs.http.address</name>
    <value>0.0.0.0:50070</value>
  </property>
  <property>
    <name>dfs.internal.nameservices</name>
    <value>ns1</value>
  </property>
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/data1/hdfs/journal</value>
  </property>
  <property>
    <name>dfs.namenode.acls.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.audit.log.async</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.balancer.request.standby</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.dir</name>
    <value>file:///data1/hdfs/namesecondary</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.period</name>
    <value>10800</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.txns</name>
    <value>10000000</value>
  </property>
  <property>
    <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.edits.dir</name>
    <value>file:///data1/hdfs/edits</value>
  </property>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>200</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.ns1.nn1</name>
    <value>172.16.219.211:50070</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.ns1.nn2</name>
    <value>172.16.219.212:50070</value>
  </property>
  <property>
    <name>dfs.namenode.http-bind-host</name>
    <value>0.0.0.0</value>
  </property>
  <property>
    <name>dfs.namenode.https-bind-host</name>
    <value>0.0.0.0</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///data1/hdfs/name</value>
  </property>
  <property>
    <name>dfs.namenode.resource.du.reserved</name>
    <value>50737418240</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.ns1.nn1</name>
    <value>172.16.219.211:8020</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.ns1.nn2</name>
    <value>172.16.219.212:8020</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-bind-host</name>
    <value>0.0.0.0</value>
  </property>
  <property>
    <name>dfs.namenode.service.handler.count</name>
    <value>200</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address.ns1.nn1</name>
    <value>172.16.219.211:8021</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address.ns1.nn2</name>
    <value>172.16.219.212:8021</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-bind-host</name>
    <value>0.0.0.0</value>
  </property>
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://172.16.219.211:8485;172.16.219.212:8485;172.16.219.213:8485/ns1</value>
  </property>
  <property>
    <name>dfs.namenode.support.allow.format</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.nameservice.id</name>
    <value>ns1</value>
  </property>
  <property>
    <name>dfs.nameservices</name>
    <value>ns1</value>
  </property>
  <property>
    <name>dfs.permissions.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.permissions.superusergroup</name>
    <value>hadoop</value>
  </property>
  <property>
    <name>dfs.qjournal.write-txns.timeout.ms</name>
    <value>90000</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
  <property>
    <name>dfs.support.append</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>fs.du.interval</name>
    <value>86400000</value>
  </property>
  <property>
    <name>fs.getspaceused.jitterMillis</name>
    <value>3600000</value>
  </property>
  <property>
    <name>fs.oss.impl.disable.cache</name>
    <value>true</value>
  </property>
  <property>
    <name>ha.zookeeper.quorum</name>
    <value>172.16.219.208,172.16.219.209,172.16.219.210</value>
  </property>
  <property>
    <name>ignore.secure.ports.for.testing</name>
    <value>true</value>
  </property>
  <property>
    <name>ipc.8020.backoff.enable</name>
    <value>true</value>
  </property>
  <property>
    <name>ipc.8020.callqueue.impl</name>
    <value>org.apache.hadoop.ipc.FairCallQueue</value>
  </property>
  <property>
    <name>ipc.server.listen.queue.size</name>
    <value>1200</value>
  </property>
  <property>
    <name>ipc.server.log.slow.rpc</name>
    <value>false</value>
  </property>
  <property>
    <name>mapreduce.job.acl-view-job</name>
    <value>*</value>
  </property>
</configuration>
